# Obsidian LLM Plugin - 監査および改善レポート

**日付:** 2026-02-15
**ステータス:** 監査完了・修正プラン策定済
**対象:** セキュリティ（最優先）、信頼性、仕様の充足度

---

## 1. セキュリティ監査結果と対応策

### [極めて重要] APIキー平文保存機能の廃止
- **問題:** `plaintext` モードが存在し、APIキーが暗号化されずに `data.json` に保存される。同期設定によっては外部に流出する致命的なリスクがある。
- **解決策:** **平文保存機能の完全削除と、既存キーの強制移行。**
- **対応例:**
    - `SecurityLevel` 型から `plaintext` を削除。
    - プラグイン起動時に `data.json` 内の `plaintextKeys` をチェックし、存在すれば `secretstorage` または `webcrypto` へ強制移行。
    - **移行完了後、`data.json` から `plaintextKeys` フィールドを物理的に削除する。**

---

## 2. バグおよび技術的信頼性への対応策

### [中] Gemini SSEパースの堅牢化
- **問題:** Gemini固有のSSEフォーマット（`alt=sse`）に対するパースが不十分。
- **解決策:** **ステートフルなバッファリングの実装。**
- **対応例:**
    - JSONが分割されて届いた場合でも、完全に揃うまでバッファリングしてパースを継続するロジックの導入。

### [中] 不完全なタグの露出防止
- **問題:** 生成中の `<vault_write>` 等のタグがUIにそのまま表示される。
- **解決策:** **生成中コンテンツの動的フィルタリング（遮蔽）。**
- **対応例:**
    - タグが開始されてから閉じられるまでの間、またはタグの断片（`<v`等）を一時的に隠蔽し、ユーザーには「処理中...」等の状態を表示する。

### [低] 差分計算によるUIブロックの解消
- **問題:** 長いノートの差分計算時にメインスレッドが止まる。
- **解決策:** **非同期処理への移行。**
- **対応例:**
    - 計算処理を `requestIdleCallback` 等で分割実行し、計算中は「計算中...」というUIフィードバックを表示する。

---

## 3. 仕様および機能の改善案

### [重要] モデルリストの動的取得
- **問題:** `constants.ts` にモデルがハードコードされており、新モデル対応にプラグイン更新が必要。
- **解決策:** **APIエンドポイントからのモデル取得機能。**
- **対応例:**
    - 設定画面に「モデルリストを更新」ボタンを追加し、`/v1/models` 等から取得。手動入力欄もフォールバックとして用意。

### [中] トークン制限の可視化
- **問題:** 送信前にトークン制限を超えているかどうかが不明。
- **解決策:** **リアルタイム・トークンメーターの導入。**
- **対応例:**
    - 入力欄付近に現在の消費量を表示。モデルの制限（例：128K）に対して 80% を超えたら警告色にする。

---

## 4. 実行ロードマップ（修正優先順位）

### **フェーズ 1: セキュリティの抜本的強化（最優先）**
1.  **平文保存機能の完全削除**、および移行・クリーンアップロジックの実装。

### **フェーズ 2: 通信とUIの信頼性向上**
1.  Gemini SSEパースの堅牢化。
2.  生成中タグの動的隠蔽フィルター。
3.  差分計算の非同期化。

### **フェーズ 3: 機能拡張とメンテナンス性**
1.  モデルリストの動的取得機能。
2.  トークン制限のUI表示。

---

## LLMエージェントへの技術的指示
- **平文保存の完全撤去:** 移行後に古いキーが残らないよう、`saveData` を呼び出して設定からフィールドを削除すること。
- **型安全:** `ChatView` における不明なメソッド呼び出し（`as any`）を解消し、インターフェースを定義すること。
- **i18n:** メッセージの追加時は `en.json` と `ja.json` の両方を更新すること。
